{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (717,1280) (791,1370) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m   test \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path[i])\n\u001b[0;32m    114\u001b[0m   path\u001b[38;5;241m.\u001b[39mappend(test)\n\u001b[1;32m--> 115\u001b[0m \u001b[43mstitch_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 103\u001b[0m, in \u001b[0;36mstitch_images\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m    100\u001b[0m warped_img, offset_x, offset_y, h_new, w_new \u001b[38;5;241m=\u001b[39m warp_perspective(images[i], M)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Blend warped image with reference image\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m panorama \u001b[38;5;241m=\u001b[39m \u001b[43mblend_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_img_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarped_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Update reference image for next iteration\u001b[39;00m\n\u001b[0;32m    106\u001b[0m reference_img \u001b[38;5;241m=\u001b[39m panorama\n",
      "Cell \u001b[1;32mIn[1], line 77\u001b[0m, in \u001b[0;36mblend_images\u001b[1;34m(img1, img2, offset_x, offset_y, h_new, w_new)\u001b[0m\n\u001b[0;32m     74\u001b[0m mask[offset_y:offset_y\u001b[38;5;241m+\u001b[39mh1, offset_x:offset_x\u001b[38;5;241m+\u001b[39mw1] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Blend images using weighted average\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m blended_img \u001b[38;5;241m=\u001b[39m (\u001b[43mimg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m img2\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m*\u001b[39m mask)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blended_img\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (717,1280) (791,1370) "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_orb_features(image):\n",
    "  # Convert image to grayscale\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Initiate ORB detector\n",
    "  orb = cv2.ORB_create()\n",
    "\n",
    "  # Find keypoints and descriptors\n",
    "  kp, descriptors = orb.detectAndCompute(gray, None)\n",
    "\n",
    "  return kp, descriptors\n",
    "\n",
    "def match_features(descriptors1, descriptors2, ratio=0.8):\n",
    "  # Create Brute Force Matcher object\n",
    "  matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "\n",
    "  # Perform matching\n",
    "  matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "  # Filter good matches based on Lowe's ratio test\n",
    "  good_matches = []\n",
    "  for m, n in matches:\n",
    "    if m.distance < ratio * n.distance:\n",
    "      good_matches.append(m)\n",
    "\n",
    "  return good_matches\n",
    "\n",
    "def get_homography(kp1, kp2, matches):\n",
    "  # Convert keypoints to numpy arrays\n",
    "  src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "  dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "  # Find homography using RANSAC\n",
    "  M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "  return M\n",
    "\n",
    "def warp_perspective(img, M):\n",
    "  # Get image height and width\n",
    "  h, w = img.shape[:2]\n",
    "\n",
    "  # Find corners of the image in the destination image\n",
    "  pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "  dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "  # Find minimum and maximum points\n",
    "  x_min = np.min(dst[:, 0, 0])\n",
    "  y_min = np.min(dst[:, 0, 1])\n",
    "  x_max = np.max(dst[:, 0, 0])\n",
    "  y_max = np.max(dst[:, 0, 1])\n",
    "\n",
    "  # Get translation offset\n",
    "  offset_x = int(-x_min)\n",
    "  offset_y = int(-y_min)\n",
    "\n",
    "  # Create new destination image with proper size\n",
    "  h_new = int(y_max - y_min)\n",
    "  w_new = int(x_max - x_min)\n",
    "  dst_img = cv2.warpPerspective(img, M, (w_new + offset_x, h_new + offset_y))\n",
    "\n",
    "  return dst_img, offset_x, offset_y, h_new, w_new\n",
    "\n",
    "def blend_images(img1, img2, offset_x, offset_y, h_new, w_new):\n",
    "  # Get image heights and widths\n",
    "  h1, w1 = img1.shape[:2]\n",
    "  h2, w2 = img2.shape[:2]\n",
    "\n",
    "  # Create mask for blending (black for image1, white for image2)\n",
    "  mask = np.zeros((h_new, w_new), np.float32)\n",
    "  mask[offset_y:offset_y+h1, offset_x:offset_x+w1] = 1.0\n",
    "\n",
    "  # Blend images using weighted average\n",
    "  blended_img = (img1.astype(np.float32) * (1 - mask) + img2.astype(np.float32) * mask)\n",
    "\n",
    "  return blended_img.astype(np.uint8)\n",
    "\n",
    "def stitch_images(images):\n",
    "    # Reference image for stitching\n",
    "    reference_img = images[0]\n",
    "    reference_img_gray = cv2.cvtColor(reference_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resulting panorama image\n",
    "    panorama = None\n",
    "\n",
    "    for i in range(1, len(images)):\n",
    "        # Find ORB features and descriptors\n",
    "        img1_kp, img1_des = find_orb_features(reference_img)\n",
    "        img2_kp, img2_des = find_orb_features(images[i])\n",
    "\n",
    "        # Match features\n",
    "        matches = match_features(img1_des, img2_des)\n",
    "\n",
    "        M = get_homography(img1_kp, img2_kp, matches)\n",
    "\n",
    "        # Warp perspective of the second image\n",
    "        warped_img, offset_x, offset_y, h_new, w_new = warp_perspective(images[i], M)\n",
    "\n",
    "        # Blend warped image with reference image\n",
    "        panorama = blend_images(reference_img_gray, warped_img, offset_x, offset_y, h_new, w_new)\n",
    "\n",
    "        # Update reference image for next iteration\n",
    "        reference_img = panorama\n",
    "\n",
    "    plt.imshow(panorama)\n",
    "\n",
    "img_path = ['Kelas1.jpg', 'Kelas2.jpg']\n",
    "path = []\n",
    "for i in range(len(img_path)):\n",
    "  test = cv2.imread(img_path[i])\n",
    "  path.append(test)\n",
    "stitch_images(path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
